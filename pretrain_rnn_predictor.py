#!/usr/bin/env python3
"""
Train a recurrent neural network to predict the next quadrotor state (position and optionally velocity)
from sequences generated by collect_solo_sequence_dataset.py.

Each dataset sequence stores consecutive simulator steps.  The model consumes the first T-1 steps
of a sequence and predicts the remaining T-1 steps in an auto-regressive (teacher-forced) fashion.
"""

import argparse
import json
import os
from datetime import datetime
from typing import Dict, Optional, Tuple

import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm


class SequenceDataset(Dataset):
    """Pairs (input_sequence, target_sequence) for next-step prediction."""

    def __init__(self, inputs: np.ndarray, targets: np.ndarray):
        """
        Args:
            inputs:  (N, T, F) array of features excluding the final timestep.
            targets: (N, T, F) array of features excluding the first timestep.
        """
        if inputs.shape != targets.shape:
            raise ValueError("inputs and targets must share the same shape.")
        self._inputs = torch.from_numpy(inputs.astype(np.float32))
        self._targets = torch.from_numpy(targets.astype(np.float32))

    def __len__(self) -> int:
        return self._inputs.shape[0]

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        return self._inputs[idx], self._targets[idx]


class RNNPredictor(nn.Module):
    """Recurrent model with configurable GRU/LSTM backbone."""

    def __init__(
        self,
        input_dim: int,
        hidden_size: int,
        num_layers: int,
        rnn_type: str,
        dropout: float,
    ):
        super().__init__()
        if num_layers < 1:
            raise ValueError("num_layers must be at least 1.")
        rnn_cls = {"gru": nn.GRU, "lstm": nn.LSTM}[rnn_type]
        rnn_dropout = dropout if num_layers > 1 else 0.0
        self.rnn = rnn_cls(
            input_dim,
            hidden_size,
            num_layers=num_layers,
            dropout=rnn_dropout,
            batch_first=True,
        )
        self.head = nn.Linear(hidden_size, input_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: (batch, seq_len, input_dim) tensor of input features.
        Returns:
            preds: (batch, seq_len, input_dim) tensor of predicted next-step features.
        """
        outputs, _ = self.rnn(x)
        preds = self.head(outputs)
        return preds


def set_seed(seed: int) -> None:
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def load_dataset(path: str) -> Dict[str, np.ndarray]:
    data = np.load(path)
    required = {"positions", "velocities"}
    missing = required - set(data.keys())
    if missing:
        raise KeyError(f"Dataset is missing required arrays: {sorted(missing)}")
    return {key: data[key] for key in required}


def assemble_sequences(
    positions: np.ndarray,
    velocities: np.ndarray,
    use_velocity: bool,
) -> np.ndarray:
    """Return the feature tensor shaped (num_sequences, seq_len, feature_dim)."""
    if positions.shape != velocities.shape:
        raise ValueError("positions and velocities must share the same shape.")
    positions = positions.astype(np.float32)
    velocities = velocities.astype(np.float32)
    if use_velocity:
        return np.concatenate([positions, velocities], axis=-1)
    return positions


def split_indices(num_sequences: int, val_fraction: float, seed: int) -> Tuple[np.ndarray, np.ndarray]:
    if not 0.0 <= val_fraction < 1.0:
        raise ValueError("val_fraction must lie in [0, 1).")
    indices = np.arange(num_sequences)
    rng = np.random.default_rng(seed)
    rng.shuffle(indices)
    val_size = int(round(num_sequences * val_fraction))
    val_indices = indices[:val_size]
    train_indices = indices[val_size:]
    if train_indices.size == 0 or val_indices.size == 0:
        raise ValueError("val_fraction results in an empty train or validation split.")
    return train_indices, val_indices


def build_dataloaders(
    features: np.ndarray,
    train_indices: np.ndarray,
    val_indices: np.ndarray,
    batch_size: int,
) -> Tuple[DataLoader, DataLoader]:
    inputs = features[:, :-1, :]
    targets = features[:, 1:, :]

    train_dataset = SequenceDataset(
        inputs[train_indices],
        targets[train_indices],
    )
    val_dataset = SequenceDataset(
        inputs[val_indices],
        targets[val_indices],
    )

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)
    return train_loader, val_loader


def train_model(
    model: nn.Module,
    train_loader: DataLoader,
    val_loader: DataLoader,
    device: torch.device,
    epochs: int,
    lr: float,
    weight_decay: float,
    grad_clip: float,
    epoch_callback=None,
) -> Tuple[list, list, float]:
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)
    model.to(device)

    train_losses, val_losses = [], []
    best_val = float("inf")

    for epoch in range(1, epochs + 1):
        model.train()
        running = 0.0
        for batch_inputs, batch_targets in train_loader:
            batch_inputs = batch_inputs.to(device)
            batch_targets = batch_targets.to(device)
            optimizer.zero_grad(set_to_none=True)
            preds = model(batch_inputs)
            loss = criterion(preds, batch_targets)
            loss.backward()
            if grad_clip is not None and grad_clip > 0.0:
                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
            optimizer.step()
            running += loss.item() * batch_inputs.size(0)
        epoch_train = running / len(train_loader.dataset)
        train_losses.append(epoch_train)

        model.eval()
        val_total = 0.0
        with torch.no_grad():
            for val_inputs, val_targets in val_loader:
                val_inputs = val_inputs.to(device)
                val_targets = val_targets.to(device)
                preds = model(val_inputs)
                loss = criterion(preds, val_targets)
                val_total += loss.item() * val_inputs.size(0)
        epoch_val = val_total / len(val_loader.dataset)
        val_losses.append(epoch_val)

        tqdm.write(
            f"[Epoch {epoch:03d}] train_loss={epoch_train:.6f} | val_loss={epoch_val:.6f}"
        )
        best_val = min(best_val, epoch_val)

        if epoch_callback is not None:
            epoch_callback(epoch, list(train_losses), list(val_losses))

    return train_losses, val_losses, best_val


def main():
    parser = argparse.ArgumentParser(description="Train an RNN next-step predictor on solo quad sequences.")
    parser.add_argument("--dataset_path", required=True, help="NPZ dataset from collect_solo_sequence_dataset.py")
    parser.add_argument("--use_velocity", action="store_true", help="Include velocity channels alongside positions.")
    parser.add_argument("--rnn_type", choices=("gru", "lstm"), default="gru", help="Recurrent cell type.")
    parser.add_argument("--hidden_size", type=int, default=256, help="Hidden state width of the RNN.")
    parser.add_argument("--num_layers", type=int, default=2, help="Number of stacked RNN layers.")
    parser.add_argument("--dropout", type=float, default=0.0, help="Dropout between RNN layers (ignored for single layer).")
    parser.add_argument("--batch_size", type=int, default=32, help="Sequences per mini-batch.")
    parser.add_argument("--epochs", type=int, default=25, help="Number of training epochs.")
    parser.add_argument("--lr", type=float, default=1e-3, help="Learning rate.")
    parser.add_argument("--weight_decay", type=float, default=0.0, help="Adam weight decay.")
    parser.add_argument("--grad_clip", type=float, default=1.0, help="Global norm gradient clipping value (<=0 to disable).")
    # Not useful metric using this dataset collection method.
    parser.add_argument("--val_fraction", type=float, default=0.1, help="Fraction of sequences reserved for validation.")
    parser.add_argument("--seed", type=int, default=42, help="Random seed.")
    parser.add_argument(
        "--device",
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Torch device string, defaults to CUDA when available.",
    )
    parser.add_argument("--train_dir", default="train_dir", help="Directory to store training artefacts.")
    parser.add_argument("--experiment_name", default=None, help="Optional subdirectory for this run.")
    args = parser.parse_args()

    set_seed(args.seed)

    data = load_dataset(args.dataset_path)
    features = assemble_sequences(data["positions"], data["velocities"], args.use_velocity)
    num_sequences, seq_len, feature_dim = features.shape
    if seq_len < 2:
        raise ValueError("Sequences must contain at least two timesteps for next-step prediction.")

    train_indices, val_indices = split_indices(num_sequences, args.val_fraction, args.seed)

    train_loader, val_loader = build_dataloaders(
        features, train_indices, val_indices, args.batch_size
    )

    model = RNNPredictor(
        input_dim=feature_dim,
        hidden_size=args.hidden_size,
        num_layers=args.num_layers,
        rnn_type=args.rnn_type,
        dropout=args.dropout,
    )
    device = torch.device(args.device)

    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    run_name = args.experiment_name or f"rnn_{timestamp}"
    run_dir = os.path.join(args.train_dir, run_name)
    os.makedirs(run_dir, exist_ok=True)

    latest_checkpoint_path: Optional[str] = None
    best_checkpoint_path: Optional[str] = None
    best_val_so_far = float("inf")

    def save_checkpoint(
        path: str,
        epoch_idx: int,
        val_loss_value: float,
        train_losses_list: list,
        val_losses_list: list,
        best_so_far: float,
    ) -> None:
        state_dict = {k: v.detach().cpu() for k, v in model.state_dict().items()}
        torch.save(
            {
                "model_state_dict": state_dict,
                "config": vars(args),
                "epoch": epoch_idx,
                "train_losses": list(train_losses_list),
                "val_losses": list(val_losses_list),
                "best_val_loss": float(best_so_far),
                "val_loss": float(val_loss_value),
            },
            path,
        )

    def epoch_callback(epoch_idx: int, train_losses_list: list, val_losses_list: list):
        nonlocal latest_checkpoint_path, best_checkpoint_path, best_val_so_far
        if not val_losses_list:
            raise RuntimeError("Validation loss history is empty; ensure val_fraction > 0.")
        val_loss_value = float(val_losses_list[-1])
        best_so_far = min(best_val_so_far, val_loss_value)

        latest_filename = f"checkpoint_latest_val{val_loss_value:.6f}.pt"
        latest_path = os.path.join(run_dir, latest_filename)
        if latest_checkpoint_path and latest_checkpoint_path != latest_path and os.path.exists(latest_checkpoint_path):
            os.remove(latest_checkpoint_path)
        save_checkpoint(latest_path, epoch_idx, val_loss_value, train_losses_list, val_losses_list, best_so_far)
        latest_checkpoint_path = latest_path

        if val_loss_value < best_val_so_far:
            best_filename = f"checkpoint_best_val{val_loss_value:.6f}.pt"
            best_path = os.path.join(run_dir, best_filename)
            if best_checkpoint_path and best_checkpoint_path != best_path and os.path.exists(best_checkpoint_path):
                os.remove(best_checkpoint_path)
            best_val_so_far = val_loss_value
            save_checkpoint(best_path, epoch_idx, val_loss_value, train_losses_list, val_losses_list, best_val_so_far)
            best_checkpoint_path = best_path
            tqdm.write(
                f"[pretrain_rnn_predictor] New best checkpoint at epoch {epoch_idx} (val_loss={val_loss_value:.6f})"
            )

    grad_clip = None if args.grad_clip <= 0.0 else args.grad_clip
    train_losses, val_losses, best_val = train_model(
        model,
        train_loader,
        val_loader,
        device=device,
        epochs=args.epochs,
        lr=args.lr,
        weight_decay=args.weight_decay,
        grad_clip=grad_clip,
        epoch_callback=epoch_callback,
    )

    final_state_dict = {k: v.detach().cpu() for k, v in model.state_dict().items()}
    artefacts = {
        "model_state_dict": final_state_dict,
        "config": vars(args),
        "best_val_loss": best_val,
        "train_losses": train_losses,
        "val_losses": val_losses,
    }
    checkpoint_path = os.path.join(run_dir, "model.pt")
    torch.save(artefacts, checkpoint_path)

    metrics_path = os.path.join(run_dir, "metrics.json")
    with open(metrics_path, "w", encoding="utf-8") as f:
        json.dump(
            {
                "train_losses": train_losses,
                "val_losses": val_losses,
                "best_val_loss": best_val,
            },
            f,
            indent=2,
        )

    summary_message = (
        f"[pretrain_rnn_predictor] Finished training on {num_sequences} sequences "
        f"(train={len(train_indices)}, val={len(val_indices)}). "
        f"Best val loss: {best_val:.6f}. Saved artefacts under {run_dir}"
    )
    print(summary_message)
    if latest_checkpoint_path:
        print(f"[pretrain_rnn_predictor] Latest checkpoint: {os.path.abspath(latest_checkpoint_path)}")
    if best_checkpoint_path:
        print(f"[pretrain_rnn_predictor] Best checkpoint: {os.path.abspath(best_checkpoint_path)}")


if __name__ == "__main__":
    main()
